% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%----------------------------------------------------------------------------------------
% CHAPTER TEMPLATE
%----------------------------------------------------------------------------------------


\chapter{Vorgehen / Methoden} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
% SECTION 1
%----------------------------------------------------------------------------------------

\section{Mining}
Damit alle Analysen durchgeführt werden konnten, musste das Mining der Projekte erweitert werden. So wurde die GraphQL Abfrage für die PullRequests erweitert, um zusätzlich den Churn als auch die Commits auf den Pull Requests zu speichern. Die Abfrage der Daten wurde durch einen neuen PullRequest Statistik API Controller ermöglicht, welcher sämtliche Daten der einzelnen PullRequests, wie etwa der Churn, die einzelnen Commits des PullRequests als auch die Anzahl geänderter Dateien zurückgibt. 

Für die einzelnen Analysen wurde jeweils ein neues Jupyter Notebook erstellt. Dieser ermöglichen eine schnelle und unkomplizierte (graphische) Auswertung der Daten. \parencite{stumpf_simon_repo-detectivesba-metric-analysis-scripts_nodate}

\section{Benötigte Metriken}


\section{Architekturbeschreibung GitGauge}
// TODO 

\section{Analyse Churn vs Latency}
\label{sec:Metriken}
Wie in Kapitel \secref{sec:PullRequestDauer} beschrieben, finden sich in der Literatur unterschiedliche Aussagen zum Einfluss der Code-Grösse (Churn) auf die Dauer von Pull Requests (PR Latency). Während einige Studien einen Zusammenhang feststellen, bleiben andere Untersuchungen uneindeutig \parencite{hasan_understanding_2023}\parencite{kudrjavets_small_2022}.

Da das GitGauge noch nicht über alle notwendigen Metriken verfügte, welche für den Zusammenhang zwischen Latency und Churn notwendig sind, müssen diese implementiert werden. Für diese Analyse wurden folgende Metriken via Mining extrahiert:
\begin{itemize}
    \item \textbf{Pull Request createTime:} Erstellungsdatum des PullRequests
    \item \textbf{Pull Request closeTime:} Schliesszeit des PullRequests.
    \item \textbf{Pull Request Additions:} Anzahl der hinzugefügten Codezeilen.
    \item \textbf{Pull Request Deletions:} Anzahl der gelöschten Codezeilen
\end{itemize}

Daraus wurden die Metriken \textit{latency} und \textit{churn} berechnet. Die \textit{latency} wird anhand folgender Formel berechnet:
\begin{equation}
latency = closeTime - createTime
\end{equation}

Die Zusammensetzung des \textit{churn} ist wie folgt:
\begin{equation}
churn = additions + deletions
\end{equation}

Mittels der Rangkorrelation nach Spearman kann überprüft werden, ob ein Zusammenhang zwischen zwei Variablen besteht. Dabei verwendet Spearman die Rangplätze der Daten und nicht deren Wert. Der daraus resultierende Korrelationskoeffizient r\textsubscript{s} kann zwischen -1 und 1 liegen, wobei dieser bei eins ein starker positiver Zusammenhang und bei -1 ein starker negativer Zusammenhang zwischen den zwei Variablen besteht. Wenn der Korrelationskoeffizient bei null liegt, besteht keine Korrelation. \parencite{noauthor_t-test_nodate}  \\
Die Formel \parencite{noauthor_t-test_nodate} stellt sich wie folgt zusammen: 
\begin{equation}
r_s = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}
\end{equation}
\label{eqn:spearman}
\noindent\textbf{Legende:}
\begin{itemize}
  \item [$r_s$] Spearman-Rangkorrelationskoeffizient
  \item[$d_i$] Differenz der Ränge zwischen den zwei Variablen 
  \item[$n$] Anzahl der beobachteten Fälle
\end{itemize}


\section{Datengrundlagen}
\label{sec:Datengrundlagen}
Als Datengrundlage dienten uns die Repositories mehrerer Schulklassen aus unterschiedlichen Jahrgängen. Es wurden 7 Teilzeit- als auch 5 Vollzeitklassen aus den Jahren 2021 - 2024 analysiert. Insgesamt wurden 71 Racetrack Repositories analysiert. 


